{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers accelerate bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T19:05:00.872954Z","iopub.execute_input":"2025-11-06T19:05:00.873165Z","iopub.status.idle":"2025-11-06T19:06:26.164529Z","shell.execute_reply.started":"2025-11-06T19:05:00.873135Z","shell.execute_reply":"2025-11-06T19:06:26.163468Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.9.0)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.19.1)\nCollecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.9.18)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.5)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.1.0)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.10)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.8.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface-hub, nvidia-cusolver-cu12, bitsandbytes\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 1.0.0rc2\n    Uninstalling huggingface-hub-1.0.0rc2:\n      Successfully uninstalled huggingface-hub-1.0.0rc2\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.48.2 huggingface-hub-0.36.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"HF_TOKEN\")\nlogin(token=hf_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T19:06:42.940984Z","iopub.execute_input":"2025-11-06T19:06:42.941788Z","iopub.status.idle":"2025-11-06T19:06:43.579221Z","shell.execute_reply.started":"2025-11-06T19:06:42.941756Z","shell.execute_reply":"2025-11-06T19:06:43.578523Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"%%writefile workers.py\nimport torch\nimport torch.multiprocessing as mp\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n# Import the cache object we need to manually reconstruct\nfrom transformers.cache_utils import DynamicCache\nimport time\nimport sys\nfrom queue import Empty\n\n# CONFIGURATION\nMODEL_ID = \"meta-llama/Meta-Llama-3-8B-Instruct\"\nMAX_NEW_TOKS = 1000 \n\n# PREFILL WORKER ---\ndef prefill_worker_loop(request_queue: mp.Queue, decode_queue: mp.Queue, tokenizer):\n    # This function runs in a separate process, pinned to CUDA:0\n    \n    device = torch.device(\"cuda:0\")\n    mp.current_process().name = \"PREFILL-WORKER-0\"\n    \n    print(f\"[{mp.current_process().name}] Initializing on {device}...\")\n    model = None # Define model as None in case loading fails\n    try:\n        quantization_config = BitsAndBytesConfig(\n            load_in_4bit=True,\n            bnb_4bit_compute_dtype=torch.bfloat16,\n            bnb_4bit_quant_type=\"nf4\",\n        )\n        \n        model = AutoModelForCausalLM.from_pretrained(\n            MODEL_ID, \n            quantization_config=quantization_config,\n            torch_dtype=torch.bfloat16,\n            device_map=device \n        )\n        model.eval()\n        print(f\"[{mp.current_process().name}] Llama 3 8B (4-bit) loaded successfully on {device}.\")\n    except Exception as e:\n        print(f\"[{mp.current_process().name}] Failed to load model on {device}: {e}\")\n        decode_queue.put(None) # Signal decode to stop\n        return\n\n    try:\n        while True:\n            try:\n                #Get a new request\n                request_data = request_queue.get(timeout=1.0)\n                \n                # Check for STOP signal (None)\n                if request_data is None:\n                    print(f\"[{mp.current_process().name}] STOP signal received. Exiting loop.\")\n                    break\n                \n                request_id, prompt_text = request_data\n                \n                print(f\"[{mp.current_process().name}] Received request {request_id}. Prefilling {len(prompt_text)} chars...\")\n                start_time = time.time()\n\n                inputs = tokenizer(\n                    prompt_text, \n                    return_tensors=\"pt\"\n                ).to(device)\n                \n                # Run the PREFILL step\n                with torch.no_grad():\n                    outputs = model(**inputs, use_cache=True)\n\n                prefill_time = time.time()\n                \n                # Extract the KV cache and logits\n                kv_cache = outputs.past_key_values\n                last_logits = outputs.logits[:, -1, :]\n                \n                # Unpack the DynamicCache and it to CPU for the queue.\n                kv_cache_cpu = tuple(\n                    (layer_cache[0].to(\"cpu\"), layer_cache[1].to(\"cpu\"))\n                    for layer_cache in kv_cache\n                )\n                last_logits_cpu = last_logits.to(\"cpu\")\n\n                before_queueing_time = time.time()\n                \n                # Send to the decode worker\n                decode_queue.put((request_id, kv_cache_cpu, last_logits_cpu))\n                \n                # This is the TTFT for the disaggregated system\n                ttft = prefill_time - start_time\n                print(f\"[{mp.current_process().name}] Request {request_id} TTFT: {ttft:.2f}s. Sent to decode queue.\")\n                \n            except Empty:\n                continue \n            except (Exception, KeyboardInterrupt) as e:\n                print(f\"[{mp.current_process().name}] Error in prefill loop: {e}\")\n                break\n    finally:\n        print(f\"[{mp.current_process().name}] Cleaning up...\")\n        # Send STOP signal to the decode worker\n        decode_queue.put(None)\n        if model:\n            del model\n        torch.cuda.empty_cache()\n        print(f\"[{mp.current_process().name}] Model unloaded from {device}. Exiting.\")\n\n\n\n# DECODE WORKER\ndef decode_worker_loop(decode_queue: mp.Queue, response_dict: dict, tokenizer):\n    # This function runs in a separate process, pinned to CUDA:1\n    \n    device = torch.device(\"cuda:1\")\n    mp.current_process().name = \"DECODE-WORKER-1\"\n\n    print(f\"[{mp.current_process().name}] Initializing on {device}...\")\n    model = None # Define model as None in case loading fails\n    try:\n        quantization_config = BitsAndBytesConfig(\n            load_in_4bit=True,\n            bnb_4bit_compute_dtype=torch.bfloat16,\n            bnb_4bit_quant_type=\"nf4\",\n        )\n        \n        model = AutoModelForCausalLM.from_pretrained(\n            MODEL_ID, \n            quantization_config=quantization_config,\n            torch_dtype=torch.bfloat16,\n            device_map=device \n        )\n        model.eval()\n        print(f\"[{mp.current_process().name}] Llama 3 8B (4-bit) loaded successfully on {device}.\")\n    except Exception as e:\n        print(f\"[{mp.current_process().name}] Failed to load model on {device}: {e}\")\n        return\n\n    try:\n        while True:\n            try:\n                # Get a prefilled request from the prefill worker\n                request_data = decode_queue.get(timeout=1.0)\n                \n                # Check for STOP signal (None)\n                if request_data is None:\n                    print(f\"[{mp.current_process().name}] STOP signal received. Exiting loop.\")\n                    break \n                \n                request_id, kv_cache_cpu, last_logits_cpu = request_data\n                \n                print(f\"[{mp.current_process().name}] Received request {request_id} for DECODING...\")\n                start_time = time.time()\n                \n                # Reconstruct a new DynamicCache object\n                kv_cache_tuple_gpu1 = tuple(\n                    (layer_cache[0].to(device), layer_cache[1].to(device))\n                    for layer_cache in kv_cache_cpu\n                )\n                kv_cache = DynamicCache()\n                kv_cache.key_cache = [layer_kv[0] for layer_kv in kv_cache_tuple_gpu1]\n                kv_cache.value_cache = [layer_kv[1] for layer_kv in kv_cache_tuple_gpu1]\n                \n                next_token_logits = last_logits_cpu.to(device)\n                \n                generated_ids = []\n                \n                with torch.no_grad():\n                    for _ in range(MAX_NEW_TOKS):\n                        # Sample the next token\n                        next_token = torch.argmax(next_token_logits, dim=-1).unsqueeze(0)\n                        \n                        # Add this check back in to match model.generate()\n                        if next_token.item() == tokenizer.eos_token_id:\n                            print(f\"[{mp.current_process().name}] Request {request_id} hit EOS token. Stopping.\")\n                            break\n                        \n                        generated_ids.append(next_token.item())\n                        \n                        # Run the DECODE step\n                        outputs = model(\n                            input_ids=next_token, \n                            past_key_values=kv_cache, \n                            use_cache=True\n                        )\n                        \n                        # Get the new cache and logits\n                        kv_cache = outputs.past_key_values\n                        next_token_logits = outputs.logits[:, -1, :] \n                \n                #Decode the final text\n                generated_text = tokenizer.decode(\n                    generated_ids, \n                    skip_special_tokens=True\n                )\n                \n                total_time = time.time() - start_time\n                num_generated = len(generated_ids)\n                \n                # Calculate decode throughput (tokens per second)\n                # This is the equivalent of 1/TPOT\n                decode_tps = num_generated / (total_time + 1e-6) \n                \n                print(f\"[{mp.current_process().name}] Request {request_id} DECODED {num_generated} tokens in {total_time:.2f}s (decode_tps: {decode_tps:.1f} tok/s).\")\n                \n\n                response_dict[request_id] = generated_text\n\n            except Empty:\n                continue\n            except (Exception, KeyboardInterrupt) as e:\n                print(f\"[{mp.current_process().name}] Error in decode loop: {e}\")\n                if 'kv_cache' in locals():\n                    print(f\"[{mp.current_process().name}] Type of kv_cache that caused error: {type(kv_cache)}\")\n                break\n    finally:\n        print(f\"[{mp.current_process().name}] Cleaning up...\")\n        if model:\n            del model\n        torch.cuda.empty_cache()\n        print(f\"[{mp.current_process().name}] Model unloaded from {device}. Exiting.\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T21:07:10.545258Z","iopub.execute_input":"2025-11-06T21:07:10.545579Z","iopub.status.idle":"2025-11-06T21:07:10.555043Z","shell.execute_reply.started":"2025-11-06T21:07:10.545559Z","shell.execute_reply":"2025-11-06T21:07:10.554387Z"}},"outputs":[{"name":"stdout","text":"Overwriting workers.py\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"import torch\nimport torch.multiprocessing as mp\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TextStreamer\nfrom kaggle_secrets import UserSecretsClient\nimport time\nimport os\nimport sys\nimport uuid\nfrom concurrent.futures import ThreadPoolExecutor\nimport torch\n\nimport workers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T21:07:14.328853Z","iopub.execute_input":"2025-11-06T21:07:14.329470Z","iopub.status.idle":"2025-11-06T21:07:14.334379Z","shell.execute_reply.started":"2025-11-06T21:07:14.329442Z","shell.execute_reply":"2025-11-06T21:07:14.333489Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"#CONFIGURATION\nMODEL_ID = \"meta-llama/Meta-Llama-3-8B-Instruct\"\nMAX_NEW_TOKS = 1000\n\n#LIGHT PREFILL / LIGHT DECODE\nPROMPT_LL_1 = \"\"\"\n<|begin_of_text|><|start_header_id|>user<|end_header_id|>\nName three planets in our solar system that have rings.\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\"\"\"\n\nPROMPT_LL_2 = \"\"\"\n<|begin_of_text|><|start_header_id|>user<|end_header_id|>\nGive me two synonyms for the word 'rapid'.\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\"\"\"\n\n# LIGHT PREFILL / HEAVY DECODE\nPROMPT_LH_1 = \"\"\"\n<|begin_of_text|><|start_header_id|>user<|end_header_id|>\nWrite a detailed 600-word essay on how artificial intelligence could transform education by 2035.\nDiscuss ethical, economic, and social implications.\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\"\"\"\n\nPROMPT_LH_2 = \"\"\"\n<|begin_of_text|><|start_header_id|>user<|end_header_id|>\nTell a long, descriptive story about a time traveler visiting ancient Egypt.\nInclude dialogue, emotions, and vivid scenery.\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\"\"\"\n\nPROMPT_LH_3 = \"\"\"\n<|begin_of_text|><|start_header_id|>user<|end_header_id|>\nGenerate an in-depth tutorial explaining how attention mechanisms work in transformer models.\nUse equations, analogies, and examples.\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\"\"\"\n\n# HEAVY PREFILL / LIGHT DECODE\nPROMPT_HL_1 = \"\"\"\n<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n[CONTEXT]\nThe following text is an excerpt from a 500-word article describing the structure and history of the Roman Republic, its Senate, and transition into the Roman Empire.\nImagine this as a long prefill input.\n[/CONTEXT]\nWho was the first Roman Emperor?\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\"\"\"\n\nPROMPT_HL_2 = \"\"\"\n<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n[CONTEXT]\nIn this extensive passage, we describe the architecture of neural networks, including activation functions, optimization methods, and backpropagation.\nThe text is about 400 tokens long.\n[/CONTEXT]\nName one commonly used activation function.\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\"\"\"\n\nPROMPT_HL_3 = \"\"\"\n<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n[CONTEXT]\nYou are given a long transcript of an academic lecture discussing the origins of the French Revolution, with references to Rousseau, Voltaire, and economic disparity in 18th-century France.\n[/CONTEXT]\nIn one line, state the main cause of the French Revolution.\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\"\"\"\n\n# HEAVY PREFILL / HEAVY DECODE\nPROMPT_HH_1 = \"\"\"\n<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n[CONTEXT]\nImagine a detailed 1,000-token report summarizing global climate change models, historical CO₂ emissions, and their socioeconomic effects.\n[/CONTEXT]\nWrite an equally long policy proposal (800–1000 words) addressing the transition to renewable energy in developing countries.\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\"\"\"\n\nPROMPT_HH_2 = \"\"\"\n<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n[CONTEXT]\nYou have just read a 700-token historical overview of the Industrial Revolution.\n[/CONTEXT]\nCompose a comprehensive essay connecting the Industrial Revolution to modern AI-driven automation, covering technological parallels and labor implications (700+ words).\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\"\"\"\n\n# Unified benchmark workload\nPROMPTS_TO_RUN = [\n    (\"p1_light_light\", PROMPT_LL_1),\n    (\"p2_light_light\", PROMPT_LL_2),\n    (\"p3_light_heavy\", PROMPT_LH_1),\n    (\"p4_light_heavy\", PROMPT_LH_2),\n    (\"p5_light_heavy\", PROMPT_LH_3),\n    (\"p6_heavy_light\", PROMPT_HL_1),\n    (\"p7_heavy_light\", PROMPT_HL_2),\n    (\"p8_heavy_light\", PROMPT_HL_3),\n    (\"p9_heavy_heavy\", PROMPT_HH_1),\n    (\"p10_heavy_heavy\", PROMPT_HH_2),\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T21:09:33.124740Z","iopub.execute_input":"2025-11-06T21:09:33.125306Z","iopub.status.idle":"2025-11-06T21:09:33.132375Z","shell.execute_reply.started":"2025-11-06T21:09:33.125282Z","shell.execute_reply":"2025-11-06T21:09:33.131484Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# ORCHESTRATOR API CLASS\nclass OrchestratorAPI:\n    def __init__(self, hf_token):\n        print(\"[ORCHESTRATOR] Initializing...\")\n        os.environ[\"HF_TOKEN\"] = hf_token\n        \n        # Set the multiprocessing start method to 'spawn' for CUDA\n        mp.set_start_method(\"spawn\", force=True)\n        \n        # Create shared queues for communication\n        self.request_queue = mp.Queue()\n        self.decode_queue = mp.Queue()\n        \n        self.manager = mp.Manager()\n        self.response_dict = self.manager.dict()\n        \n        # Load tokenizer in the main process and pass it\n        self.tokenizer = AutoTokenizer.from_pretrained(workers.MODEL_ID)\n        \n        self.prefill_process = None\n        self.decode_process = None\n        print(\"[ORCHESTRATOR] Initialization complete.\")\n\n    def start_workers(self):\n        #Starts the two worker processes\n        \n        print(\"[ORCHESTRATOR] Starting worker processes...\")\n        \n        # Start PREFILL worker\n        self.prefill_process = mp.Process(\n            target=workers.prefill_worker_loop,\n            args=(self.request_queue, self.decode_queue, self.tokenizer)\n        )\n        self.prefill_process.start()\n        \n        # Start DECODE worker\n        self.decode_process = mp.Process(\n            target=workers.decode_worker_loop,\n            args=(self.decode_queue, self.response_dict, self.tokenizer)\n        )\n        self.decode_process.start()\n        \n        print(\"[ORCHESTRATOR] Workers started. Waiting for model loading...\")\n        # Simple wait - Give 2 mins for both models to load\n        time.sleep(120) \n        print(\"[ORCHESTRATOR] Models should be loaded. System is READY.\")\n\n    def stop_workers(self):\n        # Stops the worker processes gracefully and cleans up GPU memory\n\n        print(\"[ORCHESTRATOR] Sending STOP signal to workers...\")\n        \n        # Send a \"STOP\" signal to the prefill queue\n        self.request_queue.put(None)\n        \n        \n        # Wait for the processes to exit\n        if self.prefill_process:\n            self.prefill_process.join() # Wait for prefill to exit\n            print(\"[ORCHESTRATOR] Prefill worker joined.\")\n        if self.decode_process:\n            self.decode_process.join() # Wait for decode to exit\n            print(\"[ORCHESTRATOR] Decode worker joined.\")\n            \n        self.manager.shutdown()\n        print(\"[ORCHESTRATOR] Workers stopped and cleaned up.\")\n\n    def _send_request(self, request_id, prompt):\n        #Internal method to put a request on the queue\n        print(f\"[ORCHESTRATOR] Sending request {request_id}...\")\n        self.request_queue.put((request_id, prompt))\n        return request_id\n\n    def _get_response(self, request_id, timeout=120):\n        # Internal method to poll for a response\n        \n        start_time = time.time()\n        while True:\n            if request_id in self.response_dict:\n                return self.response_dict.pop(request_id)\n            if time.time() - start_time > timeout:\n                return f\"Error: Request {request_id} timed out.\"\n            time.sleep(0.1)\n\n    def process_request_sync(self, request_id, prompt):\n        # Sends one request and waits for its specific response\n        self._send_request(request_id, prompt)\n        response = self._get_response(request_id)\n        return response\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T21:09:39.444167Z","iopub.execute_input":"2025-11-06T21:09:39.444747Z","iopub.status.idle":"2025-11-06T21:09:39.454604Z","shell.execute_reply.started":"2025-11-06T21:09:39.444725Z","shell.execute_reply":"2025-11-06T21:09:39.453716Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# MAIN EXECUTION \nif __name__ == \"__main__\":\n    \n    try:\n        token = UserSecretsClient().get_secret(\"HF_TOKEN\")\n        print(\"[ORCHESTRATOR] HF_TOKEN found.\")\n    except Exception as e:\n        print(f\"[ORCHESTRATOR] HF_TOKEN not found in Kaggle Secrets. Exiting. Error: {e}\")\n        sys.exit(1)\n\n    # Initialize and start the API\n    api = None\n    try:\n        api = OrchestratorAPI(hf_token=token)\n        api.start_workers()\n        \n        total_start_time = time.time()\n        \n        # Simulate parallel requests with a ThreadPool\n        print(f\"[ORCHESTRATOR] Submitting {len(PROMPTS_TO_RUN)} requests in parallel...\")\n        \n        request_ids = {} \n        \n        with ThreadPoolExecutor(max_workers=len(PROMPTS_TO_RUN)) as executor:\n            for req_id, prompt in PROMPTS_TO_RUN:\n                if \"long\" in req_id:\n                    time.sleep(0.1)\n                \n                # Submit the _send_request task to the thread pool\n                future = executor.submit(api._send_request, req_id, prompt)\n                request_ids[future] = req_id\n\n        print(\"[ORCHESTRATOR] All requests submitted.\")\n        \n        # Wait for all responses to come back\n        print(\"[ORCHESTRATOR] Waiting for responses...\")\n        results = {}\n        for req_id, prompt in PROMPTS_TO_RUN:\n            # Poll for the result of this specific request\n            result = api._get_response(req_id)\n            results[req_id] = result\n            print(\"---\")\n            print(f\"RESULT FOR {req_id}:\")\n            print(f\"PROMPT: {prompt[:100]}...\")\n            print(f\"RESPONSE: {result}\")\n            print(\"---\")\n\n        total_end_time = time.time()\n        \n        print(\"\\n--- FINAL REPORT (DISAGGREGATED) ---\")\n        print(f\"Total time to process all {len(PROMPTS_TO_RUN)} requests (parallel): {total_end_time - total_start_time:.2f}s\")\n\n    except Exception as e:\n        print(f\"[ORCHESTRATOR] An error occurred: {e}\")\n    finally:\n        # Clean up the worker processes\n        if api:\n            api.stop_workers()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T21:09:43.844282Z","iopub.execute_input":"2025-11-06T21:09:43.845093Z","iopub.status.idle":"2025-11-06T21:18:01.249313Z","shell.execute_reply.started":"2025-11-06T21:09:43.845054Z","shell.execute_reply":"2025-11-06T21:18:01.248386Z"}},"outputs":[{"name":"stdout","text":"[ORCHESTRATOR] HF_TOKEN found.\n[ORCHESTRATOR] Initializing...\n[ORCHESTRATOR] Initialization complete.\n[ORCHESTRATOR] Starting worker processes...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n2025-11-06 21:09:53.753027: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1762463393.773894     657 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1762463393.779766     657 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"[ORCHESTRATOR] Workers started. Waiting for model loading...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n2025-11-06 21:09:59.451441: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1762463399.472527     661 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1762463399.478566     661 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nLoading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[PREFILL-WORKER-0] Initializing on cuda:0...\n","output_type":"stream"},{"name":"stderr","text":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"[DECODE-WORKER-1] Initializing on cuda:1...\n","output_type":"stream"},{"name":"stderr","text":"Loading checkpoint shards: 100%|██████████| 4/4 [00:24<00:00,  6.06s/it]\nLoading checkpoint shards: 100%|██████████| 4/4 [00:24<00:00,  6.02s/it]\n","output_type":"stream"},{"name":"stdout","text":"[ORCHESTRATOR] Models should be loaded. System is READY.\n[ORCHESTRATOR] Submitting 10 requests in parallel...\n[ORCHESTRATOR] Sending request p1_light_light...\n[ORCHESTRATOR] Sending request p2_light_light...\n[ORCHESTRATOR] Sending request p3_light_heavy...\n[ORCHESTRATOR] Sending request p4_light_heavy...\n[ORCHESTRATOR] Sending request p5_light_heavy...\n[ORCHESTRATOR] Sending request p6_heavy_light...\n[ORCHESTRATOR] Sending request p7_heavy_light...\n[ORCHESTRATOR] Sending request p8_heavy_light...\n[ORCHESTRATOR] Sending request p9_heavy_heavy...\n[ORCHESTRATOR] Sending request p10_heavy_heavy...\n[ORCHESTRATOR] All requests submitted.\n[ORCHESTRATOR] Waiting for responses...\n---\nRESULT FOR p1_light_light:\nPROMPT: \n<|begin_of_text|><|start_header_id|>user<|end_header_id|>\nName three planets in our solar system th...\nRESPONSE: Here are three planets in our solar system that have rings:\n\n1. Saturn\n2. Jupiter\n3. Uranus\n---\n---\nRESULT FOR p2_light_light:\nPROMPT: \n<|begin_of_text|><|start_header_id|>user<|end_header_id|>\nGive me two synonyms for the word 'rapid'...\nRESPONSE: Here are two synonyms for the word \"rapid\":\n\n1. Quick\n2. Swift\n---\n---\nRESULT FOR p3_light_heavy:\nPROMPT: \n<|begin_of_text|><|start_header_id|>user<|end_header_id|>\nWrite a detailed 600-word essay on how ar...\nRESPONSE: By 2035, artificial intelligence (AI) is expected to revolutionize the education sector, transforming the way students learn, teachers teach, and institutions operate. AI has the potential to improve educational outcomes, increase accessibility, and enhance the overall learning experience. However, it also raises important ethical, economic, and social implications that must be considered.\n\nOne of the most significant ways AI could transform education is through personalized learning. AI-powered adaptive learning systems can analyze a student's strengths, weaknesses, and learning style to provide tailored instruction and feedback. This approach can help students learn more efficiently, as they are presented with content that is relevant to their needs and abilities. AI can also help identify knowledge gaps and provide targeted support to students who may be struggling.\n\nAI can also enhance the teaching profession by automating routine tasks, freeing up teachers to focus on more complex and creative tasks. AI-powered grading systems, for example, can quickly and accurately assess student performance, reducing the workload of teachers and allowing them to focus on more important tasks. AI can also help teachers develop more effective lesson plans and provide real-time feedback to students.\n\nAnother area where AI can make a significant impact is in language learning. AI-powered language learning systems can provide personalized language instruction, conversational practice, and feedback to students. This can be particularly beneficial for students who are learning a new language, as AI can help them develop conversational skills and build confidence in their language abilities.\n\nAI can also transform the way we assess student learning. AI-powered assessments can provide more accurate and reliable feedback to students, helping them track their progress and identify areas where they need to improve. AI can also help identify biases in traditional assessment methods, ensuring that students are evaluated fairly and without bias.\n\nHowever, the integration of AI in education also raises important ethical concerns. One of the most significant concerns is the potential for AI to perpetuate existing social and economic inequalities. If AI-powered educational systems are not designed with equity in mind, they may exacerbate existing disparities in access to education and perpetuate systemic inequalities.\n\nAnother ethical concern is the potential for AI to replace human teachers. While AI can automate many tasks, it is unlikely to replace the complex and nuanced interactions that occur between teachers and students. However, the potential for AI to displace teachers is a real concern, particularly in areas where there is a shortage of qualified educators.\n\nEconomically, the integration of AI in education is likely to have significant benefits. AI-powered educational systems can help reduce costs associated with traditional teaching methods, such as textbooks and teacher training. AI can also help increase access to education, particularly in areas where there is a shortage of qualified teachers or limited access to educational resources.\n\nSocially, the integration of AI in education is likely to have significant benefits. AI-powered educational systems can help increase social mobility, particularly for students from disadvantaged backgrounds. AI can also help promote diversity and inclusion, as it can provide personalized instruction and feedback to students with different learning styles and abilities.\n\nIn conclusion, the integration of AI in education by 2035 has the potential to transform the way we learn, teach, and assess student performance. AI can provide personalized instruction, automate routine tasks, and increase access to education. However, it also raises important ethical, economic, and social implications that must be considered. As we move forward with the integration of AI in education, it is essential that we prioritize equity, diversity, and inclusion, and ensure that AI-powered educational systems are designed to benefit all students, regardless of their background or abilities.\n\nTo achieve this, educators, policymakers, and industry leaders must work together to develop AI-powered educational systems that are transparent, accountable, and equitable. This includes ensuring that AI-powered educational systems are designed with diverse learning styles and abilities in mind, and that they provide opportunities for students to develop critical thinking, creativity, and problem-solving skills.\n\nUltimately, the integration of AI in education has the potential to revolutionize the way we learn and teach. By prioritizing equity, diversity, and inclusion, we can ensure that AI-powered educational systems benefit all students, and that they help create a more just and equitable society.\n---\n---\nRESULT FOR p4_light_heavy:\nPROMPT: \n<|begin_of_text|><|start_header_id|>user<|end_header_id|>\nTell a long, descriptive story about a ti...\nRESPONSE: The sun beat down upon the dusty streets of ancient Thebes, casting a golden glow over the bustling city. The air was thick with the scent of frankincense and myrrh, wafting from the temples and market stalls. Amidst the chaos, a lone figure emerged from the shadows, her eyes scanning the vibrant scene before her.\n\nLena, a time traveler from the 21st century, had always been fascinated by ancient Egypt. She had spent countless hours studying the history, mythology, and culture of this ancient civilization. And now, she had finally found herself transported back in time to the very era she had always dreamed of experiencing.\n\nAs she walked through the city, Lena marveled at the towering temples, the intricate hieroglyphics, and the vibrant colors that adorned the buildings. She felt as though she had stepped into a living, breathing tapestry, woven from the threads of history and imagination.\n\nAs she turned a corner, Lena stumbled upon a group of priests, gathered around a magnificent stone statue of Anubis, the god of the dead. They were performing a ritual, their voices rising and falling in a hypnotic chant. Lena felt a shiver run down her spine as she watched, mesmerized by the ancient ceremony.\n\nOne of the priests, an elderly man with a kind face, noticed her presence and approached her. \"Greetings, traveler,\" he said, his voice low and soothing. \"What brings you to our city?\"\n\nLena hesitated, unsure of how much to reveal. \"I...I am a scholar,\" she said finally. \"I've come to learn more about your culture.\"\n\nThe priest's eyes narrowed, his expression skeptical. \"A scholar, you say? But you are not like the others. Your garb is strange, and your eyes...they hold a light that is not of this world.\"\n\nLena smiled, feeling a sense of excitement and trepidation. \"Perhaps I am not like the others,\" she said. \"But I assure you, my intentions are pure. I mean no harm, and I wish to learn.\"\n\nThe priest regarded her for a moment, then nodded. \"Very well, traveler. I am Imhotep, a priest of Anubis. I will show you the wonders of our city, and share with you the secrets of our people.\"\n\nAs the days passed, Lena found herself immersed in the daily life of ancient Thebes. She learned about the intricate hierarchies of the pharaohs, the rituals and ceremonies that governed the city, and the myths and legends that had been passed down through generations. She marveled at the stunning architecture, the vibrant colors, and the intricate carvings that adorned the temples and tombs.\n\nBut as the days turned into weeks, Lena began to feel a growing sense of unease. She knew that she was a stranger in a strange land, and that her presence was not without risk. She had seen the harsh realities of ancient Egypt, the brutal treatment of slaves, the endless wars and conflicts that had ravaged the land.\n\nOne night, as she sat on the banks of the Nile, watching the stars twinkle to life above, Lena felt a sense of longing wash over her. She missed her own time, her own world, and the people she loved. She knew that she would have to return to her own era eventually, but for now, she was content to soak up the beauty and wonder of ancient Egypt.\n\nAs she sat there, lost in thought, a figure emerged from the shadows. It was Imhotep, the priest who had taken her under his wing. He sat down beside her, his eyes shining with a deep wisdom.\n\n\"You are a curious one, traveler,\" he said. \"You see the beauty and the wonder of our city, but you also see the darkness and the pain. You are torn between two worlds, are you not?\"\n\nLena nodded, feeling a sense of vulnerability wash over her. \"Yes, I am,\" she said. \"I am torn between the world I left behind, and the world I have found here.\"\n\nImhotep placed a gentle hand on her shoulder. \"You are not alone, traveler,\" he said. \"We all are torn between the light and the darkness. But it is in the balance of these two forces that we find our true power. Remember this, and you will find your way.\"\n\nAs the night wore on, Lena felt a sense of peace settle over her. She knew that she would have to return to her own time eventually, but she also knew that she would never forget the lessons she had learned in ancient Egypt. She had discovered a new world, a world of wonder and magic, and she had discovered a new part of herself, a part that was strong and resilient.\n\nAs she stood up to leave, Imhotep placed a small, intricately carved stone in her hand. \"A\n---\n---\nRESULT FOR p5_light_heavy:\nPROMPT: \n<|begin_of_text|><|start_header_id|>user<|end_header_id|>\nGenerate an in-depth tutorial explaining ...\nRESPONSE: **Introduction**\n\nAttention mechanisms are a crucial component of transformer models, allowing them to focus on specific parts of the input sequence while processing it. In this tutorial, we'll dive into the details of how attention mechanisms work, using equations, analogies, and examples to make it easier to understand.\n\n**What is Attention?**\n\nAttention is a mechanism that allows a model to selectively focus on certain parts of the input sequence while processing it. This is particularly useful when dealing with long-range dependencies, where the model needs to consider information from distant parts of the sequence.\n\n**The Need for Attention**\n\nImagine you're trying to understand a long story. You might need to revisit certain parts of the story to understand the context, but you don't need to re-read the entire story. Attention allows the model to do the same thing, focusing on specific parts of the input sequence to extract relevant information.\n\n**The Attention Mechanism**\n\nThe attention mechanism consists of three main components:\n\n1. **Query (Q)**: The query is the input sequence that the model is trying to process. It's the \"question\" that the model is trying to answer.\n2. **Key (K)**: The key is a set of vectors that represent the input sequence. It's the \"answer\" that the model is trying to find.\n3. **Value (V)**: The value is another set of vectors that represent the input sequence. It's the \"information\" that the model is trying to extract.\n\n**The Attention Calculation**\n\nThe attention calculation is performed using the following equation:\n\n`Attention(Q, K, V) = softmax(Q * K^T) * V`\n\nWhere `*` denotes matrix multiplication, and `softmax` is a function that normalizes the output to ensure it's a probability distribution.\n\n**Breaking it Down**\n\nLet's break down the attention calculation step by step:\n\n1. `Q * K^T`: This is the dot product of the query and key vectors. It's a measure of how similar the query is to each key.\n2. `softmax(Q * K^T)`: This is the softmax function applied to the dot product. It normalizes the output to ensure it's a probability distribution, where the sum of the probabilities is 1.\n3. `softmax(Q * K^T) * V`: This is the weighted sum of the value vectors, where the weights are the attention probabilities.\n\n**Example**\n\nSuppose we have a sequence of 5 words: \"The quick brown fox jumps over the lazy dog\".\n\n* `Q` is the input sequence, represented as a set of vectors.\n* `K` is a set of vectors that represent the input sequence, where each vector corresponds to a word in the sequence.\n* `V` is another set of vectors that represent the input sequence, where each vector corresponds to a word in the sequence.\n\nThe attention mechanism calculates the attention weights by taking the dot product of `Q` and `K`, and then applying the softmax function. The attention weights are then used to compute the weighted sum of the value vectors.\n\n**Multi-Head Attention**\n\nIn the original transformer paper, the authors introduced the concept of multi-head attention, which allows the model to attend to different parts of the input sequence in parallel. This is achieved by computing multiple attention weights and concatenating them.\n\n`MultiHead(Q, K, V) = Concat(head1, head2,..., headH) * WO`\n\nWhere `head1`, `head2`,..., `headH` are the attention weights computed using different attention mechanisms, and `WO` is a learned linear transformation.\n\n**Conclusion**\n\nIn this tutorial, we've explored the attention mechanism in transformer models, including the query, key, and value vectors, and the attention calculation. We've also seen how attention allows the model to focus on specific parts of the input sequence while processing it. Finally, we've introduced the concept of multi-head attention, which allows the model to attend to different parts of the input sequence in parallel.\n\n**Additional Resources**\n\n* The original transformer paper: \"Attention Is All You Need\" by Vaswani et al. (2017)\n* A more detailed explanation of attention mechanisms: \"Attention Mechanisms in Deep Learning\" by Yann LeCun (2019)\n\nI hope this tutorial has helped you understand attention mechanisms in transformer models!\n---\n---\nRESULT FOR p6_heavy_light:\nPROMPT: \n<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n[CONTEXT]\nThe following text is an excerp...\nRESPONSE: According to the text, the transition from the Roman Republic to the Roman Empire occurred when Julius Caesar, a powerful Roman general and statesman, was appointed dictator for life by the Roman Senate. However, his assassination in 44 BCE led to a power struggle, and his adopted son and heir, Octavian (later known as Augustus), emerged victorious. Octavian became the first Roman Emperor, marking the beginning of the Roman Empire.\n---\n---\nRESULT FOR p7_heavy_light:\nPROMPT: \n<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n[CONTEXT]\nIn this extensive passage, we d...\nRESPONSE: One commonly used activation function is the Sigmoid function.\n---\n---\nRESULT FOR p8_heavy_light:\nPROMPT: \n<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n[CONTEXT]\nYou are given a long transcript...\nRESPONSE: The main cause of the French Revolution was the economic disparity and social inequality in 18th-century France, exacerbated by the absolute monarchy and the privileges of the nobility and clergy, which led to widespread discontent and ultimately, the overthrow of the monarchy.\n---\n---\nRESULT FOR p9_heavy_heavy:\nPROMPT: \n<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n[CONTEXT]\nImagine a detailed 1,000-token ...\nRESPONSE: **Policy Proposal: Accelerating the Transition to Renewable Energy in Developing Countries**\n\n**Executive Summary**\n\nThe urgent need to mitigate climate change and ensure sustainable development in developing countries necessitates a comprehensive policy framework to accelerate the transition to renewable energy. This proposal outlines a multi-faceted approach to support developing countries in their efforts to reduce greenhouse gas emissions, promote energy access, and foster economic growth.\n\n**I. Introduction**\n\nThe Intergovernmental Panel on Climate Change (IPCC) warns that global warming must be limited to 1.5°C above pre-industrial levels to avoid catastrophic consequences. Developing countries, responsible for a significant portion of global emissions, require targeted support to transition to renewable energy and achieve sustainable development. This proposal outlines a policy framework to address the unique challenges and opportunities in developing countries.\n\n**II. Historical Context**\n\nGlobal CO₂ emissions have increased by 50% since 1990, with developing countries accounting for 60% of the total. Historical emissions have been driven by fossil fuel consumption, deforestation, and land-use changes. The consequences of climate change are already evident, including more frequent natural disasters, water scarcity, and food insecurity.\n\n**III. Renewable Energy Potential**\n\nRenewable energy sources, such as solar, wind, and hydroelectric power, offer a viable alternative to fossil fuels. Developing countries have significant renewable energy potential, with solar and wind resources particularly abundant in regions like Africa and Asia. The International Renewable Energy Agency (IRENA) estimates that developing countries can generate 60% of their electricity from renewable sources by 2050.\n\n**IV. Policy Recommendations**\n\n1. **Renewable Energy Targets**: Establish national renewable energy targets for developing countries, with a focus on solar and wind power. This will create a clear roadmap for investment and policy alignment.\n2. **Grid Integration**: Develop grid infrastructure to accommodate intermittent renewable energy sources. This includes energy storage, smart grids, and grid management systems.\n3. **Financing Mechanisms**: Establish a dedicated financing mechanism to support renewable energy projects in developing countries. This could include a Green Climate Fund, public-private partnerships, and blended finance initiatives.\n4. **Capacity Building**: Provide training and capacity-building programs for local communities, governments, and private sector actors to develop the necessary skills and expertise for renewable energy development.\n5. **Grid Connection**: Develop grid connection infrastructure to enable the integration of renewable energy sources into the grid. This includes transmission lines, substations, and grid management systems.\n6. **Energy Access**: Prioritize energy access for all, with a focus on off-grid and mini-grid solutions. This includes decentralized renewable energy systems, energy storage, and energy-efficient appliances.\n7. **Carbon Pricing**: Implement carbon pricing mechanisms to provide a financial incentive for reducing emissions. This could include carbon taxes, carbon credits, or cap-and-trade systems.\n8. **International Cooperation**: Foster international cooperation to share knowledge, technology, and best practices in renewable energy development. This includes South-South cooperation, technology transfer, and capacity-building programs.\n\n**V. Implementation and Monitoring**\n\n1. **National Renewable Energy Action Plans**: Develop national renewable energy action plans to guide the transition to renewable energy. These plans should be developed in consultation with stakeholders and include clear targets, timelines, and implementation strategies.\n2. **Monitoring and Reporting**: Establish a monitoring and reporting framework to track progress towards renewable energy targets. This includes regular reporting on emissions reductions, renewable energy deployment, and energy access.\n3. **International Support**: Provide international support to developing countries through technical assistance, capacity-building programs, and financing mechanisms.\n4. **Private Sector Engagement**: Engage the private sector in the transition to renewable energy through public-private partnerships, joint ventures, and private sector financing mechanisms.\n\n**VI. Conclusion**\n\nThe transition to renewable energy in developing countries is critical for mitigating climate change, promoting sustainable development, and ensuring energy access. This policy proposal outlines a comprehensive framework to support developing countries in their efforts to reduce greenhouse gas emissions and achieve sustainable development. The proposed measures will require international cooperation, financing, and technical assistance to ensure a successful transition to a low-carbon economy.\n---\n---\nRESULT FOR p10_heavy_heavy:\nPROMPT: \n<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n[CONTEXT]\nYou have just read a 700-token ...\nRESPONSE: The Industrial Revolution, which spanned the late 18th and early 19th centuries, was a transformative period in human history that saw the widespread adoption of machines and factories, leading to unprecedented economic growth and social change. Fast-forward to the present day, and we find ourselves in the midst of another technological revolution, driven by the rapid development of artificial intelligence (AI) and automation. In this essay, we will explore the parallels between the Industrial Revolution and the current AI-driven automation era, examining the technological advancements, labor implications, and societal consequences of these two transformative periods.\n\nOne of the most striking parallels between the Industrial Revolution and the current AI-driven automation era is the introduction of new technologies that have the potential to disrupt traditional industries and ways of working. During the Industrial Revolution, the introduction of steam power, textile machinery, and other innovations enabled mass production and transformed the manufacturing landscape. Similarly, AI and automation technologies, such as machine learning, natural language processing, and robotics, are revolutionizing industries such as manufacturing, logistics, and services. These technologies have the potential to increase efficiency, reduce costs, and improve product quality, much like their predecessors did during the Industrial Revolution.\n\nAnother significant parallel is the impact of these technologies on the workforce. During the Industrial Revolution, the introduction of machines and factories led to the displacement of skilled craftsmen and the emergence of a new class of industrial workers. Similarly, the current AI-driven automation era is leading to the displacement of certain jobs, particularly those that involve repetitive or routine tasks. According to a report by the McKinsey Global Institute, up to 800 million jobs could be lost worldwide due to automation by 2030. However, this displacement is not necessarily a negative outcome, as it also creates new opportunities for workers to upskill and reskill in emerging fields such as AI development, data analysis, and digital marketing.\n\nThe Industrial Revolution also saw the emergence of new social classes and the growth of urban centers. As workers moved from rural areas to cities to work in factories, new social structures and cultural norms emerged. Similarly, the current AI-driven automation era is leading to the growth of new industries and the emergence of new social classes. The rise of the gig economy, for example, has given rise to a new class of freelancers and entrepreneurs who are leveraging AI and automation to create new business opportunities.\n\nHowever, the labor implications of the current AI-driven automation era are more complex and nuanced than those of the Industrial Revolution. While the Industrial Revolution led to the displacement of certain jobs, it also created new opportunities for workers to find employment in emerging industries. In contrast, the current AI-driven automation era is leading to the displacement of jobs that are less likely to be replaced by machines, such as those in the service sector. This has raised concerns about the potential for widespread unemployment and social unrest.\n\nFurthermore, the current AI-driven automation era is also raising questions about the distribution of wealth and power. During the Industrial Revolution, the owners of factories and machines accumulated vast wealth and power, while workers were left to fight for better working conditions and fair wages. Similarly, the current AI-driven automation era is leading to the concentration of wealth and power in the hands of a few tech giants and entrepreneurs, while workers are left to fight for a share of the benefits.\n\nIn conclusion, the parallels between the Industrial Revolution and the current AI-driven automation era are striking. Both periods have seen the introduction of new technologies that have transformed industries and ways of working. However, the labor implications of the current AI-driven automation era are more complex and nuanced than those of the Industrial Revolution. While the displacement of jobs is a reality, it also creates new opportunities for workers to upskill and reskill in emerging fields. Ultimately, the key to navigating this period of technological change is to ensure that the benefits of AI-driven automation are shared fairly and that workers are equipped with the skills and training needed to thrive in a rapidly changing world.\n---\n\n--- FINAL REPORT (DISAGGREGATED) ---\nTotal time to process all 10 requests (parallel): 362.64s\n[ORCHESTRATOR] Sending STOP signal to workers...\n[DECODE-WORKER-1] Llama 3 8B (4-bit) loaded successfully on cuda:1.\n[DECODE-WORKER-1] Received request p1_light_light for DECODING...\n[DECODE-WORKER-1] Request p1_light_light hit EOS token. Stopping.\n[DECODE-WORKER-1] Request p1_light_light DECODED 24 tokens in 2.11s (decode_tps: 11.4 tok/s).\n[DECODE-WORKER-1] Received request p2_light_light for DECODING...\n[DECODE-WORKER-1] Request p2_light_light hit EOS token. Stopping.\n[DECODE-WORKER-1] Request p2_light_light DECODED 17 tokens in 1.30s (decode_tps: 13.1 tok/s).\n[DECODE-WORKER-1] Received request p3_light_heavy for DECODING...\n[DECODE-WORKER-1] Request p3_light_heavy hit EOS token. Stopping.\n[DECODE-WORKER-1] Request p3_light_heavy DECODED 831 tokens in 64.36s (decode_tps: 12.9 tok/s).\n[DECODE-WORKER-1] Received request p4_light_heavy for DECODING...\n[DECODE-WORKER-1] Request p4_light_heavy DECODED 1000 tokens in 81.82s (decode_tps: 12.2 tok/s).\n[DECODE-WORKER-1] Received request p5_light_heavy for DECODING...\n[DECODE-WORKER-1] Request p5_light_heavy hit EOS token. Stopping.\n[DECODE-WORKER-1] Request p5_light_heavy DECODED 885 tokens in 71.16s (decode_tps: 12.4 tok/s).\n[DECODE-WORKER-1] Received request p6_heavy_light for DECODING...\n[DECODE-WORKER-1] Request p6_heavy_light hit EOS token. Stopping.\n[DECODE-WORKER-1] Request p6_heavy_light DECODED 87 tokens in 6.26s (decode_tps: 13.9 tok/s).\n[DECODE-WORKER-1] Received request p7_heavy_light for DECODING...\n[DECODE-WORKER-1] Request p7_heavy_light hit EOS token. Stopping.\n[DECODE-WORKER-1] Request p7_heavy_light DECODED 11 tokens in 0.83s (decode_tps: 13.3 tok/s).\n[DECODE-WORKER-1] Received request p8_heavy_light for DECODING...\n[DECODE-WORKER-1] Request p8_heavy_light hit EOS token. Stopping.\n[DECODE-WORKER-1] Request p8_heavy_light DECODED 50 tokens in 3.60s (decode_tps: 13.9 tok/s).\n[DECODE-WORKER-1] Received request p9_heavy_heavy for DECODING...\n[DECODE-WORKER-1] Request p9_heavy_heavy hit EOS token. Stopping.\n[DECODE-WORKER-1] Request p9_heavy_heavy DECODED 832 tokens in 66.73s (decode_tps: 12.5 tok/s).\n[DECODE-WORKER-1] Received request p10_heavy_heavy for DECODING...\n[DECODE-WORKER-1] Request p10_heavy_heavy hit EOS token. Stopping.\n[DECODE-WORKER-1] Request p10_heavy_heavy DECODED 792 tokens in 63.18s (decode_tps: 12.5 tok/s).\n[DECODE-WORKER-1] STOP signal received. Exiting loop.\n[DECODE-WORKER-1] Cleaning up...\n[DECODE-WORKER-1] Model unloaded from cuda:1. Exiting.\n[PREFILL-WORKER-0] Llama 3 8B (4-bit) loaded successfully on cuda:0.\n[PREFILL-WORKER-0] Received request p1_light_light. Prefilling 171 chars...\n[PREFILL-WORKER-0] Request p1_light_light TTFT: 0.52s. Sent to decode queue.\n[PREFILL-WORKER-0] Received request p2_light_light. Prefilling 158 chars...\n[PREFILL-WORKER-0] Request p2_light_light TTFT: 0.28s. Sent to decode queue.\n[PREFILL-WORKER-0] Received request p3_light_heavy. Prefilling 265 chars...\n[PREFILL-WORKER-0] Request p3_light_heavy TTFT: 0.29s. Sent to decode queue.\n[PREFILL-WORKER-0] Received request p4_light_heavy. Prefilling 239 chars...\n[PREFILL-WORKER-0] Request p4_light_heavy TTFT: 0.29s. Sent to decode queue.\n[PREFILL-WORKER-0] Received request p5_light_heavy. Prefilling 249 chars...\n[PREFILL-WORKER-0] Request p5_light_heavy TTFT: 0.29s. Sent to decode queue.\n[PREFILL-WORKER-0] Received request p6_heavy_light. Prefilling 374 chars...\n[PREFILL-WORKER-0] Request p6_heavy_light TTFT: 0.46s. Sent to decode queue.\n[PREFILL-WORKER-0] Received request p7_heavy_light. Prefilling 366 chars...\n[PREFILL-WORKER-0] Request p7_heavy_light TTFT: 0.30s. Sent to decode queue.\n[PREFILL-WORKER-0] Received request p8_heavy_light. Prefilling 386 chars...\n[PREFILL-WORKER-0] Request p8_heavy_light TTFT: 0.46s. Sent to decode queue.\n[PREFILL-WORKER-0] Received request p9_heavy_heavy. Prefilling 401 chars...\n[PREFILL-WORKER-0] Request p9_heavy_heavy TTFT: 0.46s. Sent to decode queue.\n[PREFILL-WORKER-0] Received request p10_heavy_heavy. Prefilling 386 chars...\n[PREFILL-WORKER-0] Request p10_heavy_heavy TTFT: 0.30s. Sent to decode queue.\n[PREFILL-WORKER-0] STOP signal received. Exiting loop.\n[PREFILL-WORKER-0] Cleaning up...\n[PREFILL-WORKER-0] Model unloaded from cuda:0. Exiting.\n[ORCHESTRATOR] Prefill worker joined.\n[ORCHESTRATOR] Decode worker joined.\n[ORCHESTRATOR] Workers stopped and cleaned up.\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"#Custom Streamer for Benchmarking\nclass BenchmarkStreamer:\n    \"\"\"\n    A simple, non-printing streamer that records:\n      - start_time (should be set externally right before generation starts)\n      - first_token_time (set when first token arrives via put)\n      - end_time (updated on every token put; final end_time is used)\n      - token_count\n    \"\"\"\n    def __init__(self):\n        self.start_time = None\n        self.first_token_time = None\n        self.end_time = None\n        self.token_count = 0\n\n    def put(self, value):\n        now = time.time()\n        # Set first_token_time the moment we get the first token\n        if self.first_token_time is None:\n            self.first_token_time = now\n            \n        # update end_time and token count for each token\n        self.end_time = now\n        self.token_count += 1\n\n    # optional method used by some transformers streamers (no-op)\n    def end(self):\n        self.end_time = time.time()\n\n    def get_stats(self):\n        \"\"\"\n        Returns (ttft_seconds, tpot_seconds_per_token, token_count)\n        - ttft = time from start_time to first token\n        - tpot = average time per-token AFTER the first token\n        If start_time was not set or no tokens were produced, return zeros.\n        \"\"\"\n        if self.start_time is None or self.first_token_time is None:\n            # Not started or no tokens produced\n            return 0.0, 0.0, 0\n\n        ttft = self.first_token_time - self.start_time\n\n        # Ensure end_time is set (if not set, assume last token time equals first token time)\n        if self.end_time is None:\n            self.end_time = self.first_token_time\n\n        # TPOT = avg time per token after the first token\n        if self.token_count > 1:\n            decode_time_after_first = self.end_time - self.first_token_time\n            tpot = decode_time_after_first / (self.token_count - 1)\n        else:\n            tpot = 0.0\n\n        return ttft, tpot, self.token_count\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T21:18:57.685188Z","iopub.execute_input":"2025-11-06T21:18:57.685743Z","iopub.status.idle":"2025-11-06T21:18:57.693184Z","shell.execute_reply.started":"2025-11-06T21:18:57.685719Z","shell.execute_reply":"2025-11-06T21:18:57.691948Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# MAIN MONOLITHIC EXECUTION\nif __name__ == \"__main__\":\n\n    try:\n        token = UserSecretsClient().get_secret(\"HF_TOKEN\")\n        os.environ[\"HF_TOKEN\"] = token\n        print(\"[MONOLITHIC] HF_TOKEN found.\")\n    except Exception as e:\n        print(f\"[MONOLITHIC] HF_TOKEN not found in Kaggle Secrets. Exiting. Error: {e}\")\n        sys.exit(1)\n\n    # Load Model and Tokenizer on ONE GPU\n    device = torch.device(\"cuda:1\")\n    print(f\"[MONOLITHIC] Initializing on {device}...\")\n    model = None\n    tokenizer = None\n    try:\n        quantization_config = BitsAndBytesConfig(\n            load_in_4bit=True,\n            bnb_4bit_compute_dtype=torch.bfloat16,\n            bnb_4bit_quant_type=\"nf4\",\n        )\n        \n        model = AutoModelForCausalLM.from_pretrained(\n            MODEL_ID, \n            quantization_config=quantization_config,\n            torch_dtype=torch.bfloat16,\n            device_map=device\n        )\n        model.eval()\n        \n        tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n        \n        print(f\"[MONOLITHIC] Llama 3 8B (4-bit) loaded successfully on {device}.\")\n    except Exception as e:\n        print(f\"[MONOLITHIC] Failed to load model: {e}\")\n        sys.exit(1)\n\n    # 3. Run workload SEQUENTIALLY\n    print(f\"[MONOLITHIC] Running {len(PROMPTS_TO_RUN)} requests sequentially...\")\n    \n    total_start_time = time.time()\n    \n    for req_id, prompt in PROMPTS_TO_RUN:\n        print(f\"\\n--- Processing {req_id} ---\")\n\n        # Create a new streamer for this request\n        streamer = BenchmarkStreamer()\n        \n        streamer.start_time = time.time()\n        prompt_start_time = streamer.start_time\n        \n        inputs = tokenizer(\n            prompt,\n            return_tensors=\"pt\"\n        ).to(device)\n        \n        # Run generation with the streamer\n        with torch.no_grad():\n            outputs = model.generate(\n                **inputs,\n                max_new_tokens=MAX_NEW_TOKS,\n                eos_token_id=tokenizer.eos_token_id,\n                streamer=streamer\n            )\n        \n        # Decode the output\n        generated_ids = outputs[0][inputs.input_ids.shape[1]:]\n        generated_text = tokenizer.decode(\n            generated_ids,\n            skip_special_tokens=True\n        )\n        \n        prompt_end_time = time.time()\n        \n        #Get stats from the streamer\n        ttft, tpot, token_count = streamer.get_stats()\n        \n        # Handle division by 0\n        if tpot > 0:\n            decode_tps = 1.0 / tpot\n        else:\n            decode_tps = 0.0\n\n        print(f\"PROMPT: {prompt[:100]}...\")\n        print(f\"RESPONSE: {generated_text}\")\n        print(f\"Time: {prompt_end_time - prompt_start_time:.2f}s ... TTFT: {ttft*1000:.2f} ms ({decode_tps:.1f} tok/s) | Tokens: {token_count}\")\n        \n    total_end_time = time.time()\n\n    print(\"\\n--- FINAL REPORT (MONOLITHIC) ---\")\n    print(f\"Total time to process all {len(PROMPTS_TO_RUN)} requests (sequential): {total_end_time - total_start_time:.2f}s\")\n    \n    # Clean up GPU memory\n    del model\n    del tokenizer\n    torch.cuda.empty_cache()\n    print(\"[MONOLITHIC] Model unloaded and GPU memory cleaned.\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T21:28:58.156357Z","iopub.execute_input":"2025-11-06T21:28:58.157182Z","iopub.status.idle":"2025-11-06T21:35:48.757994Z","shell.execute_reply.started":"2025-11-06T21:28:58.157156Z","shell.execute_reply":"2025-11-06T21:35:48.757170Z"}},"outputs":[{"name":"stdout","text":"[MONOLITHIC] HF_TOKEN found.\n[MONOLITHIC] Initializing on cuda:1...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eed10e518544400eaa197f57fb8b4703"}},"metadata":{}},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"[MONOLITHIC] Llama 3 8B (4-bit) loaded successfully on cuda:1.\n[MONOLITHIC] Running 10 requests sequentially...\n\n--- Processing p1_light_light ---\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"PROMPT: \n<|begin_of_text|><|start_header_id|>user<|end_header_id|>\nName three planets in our solar system th...\nRESPONSE: Here are three planets in our solar system that have rings:\n\n1. Saturn\n2. Jupiter\n3. Uranus\nTime: 2.47s ... TTFT: 2.84 ms (10.1 tok/s) | Tokens: 26\n\n--- Processing p2_light_light ---\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"PROMPT: \n<|begin_of_text|><|start_header_id|>user<|end_header_id|>\nGive me two synonyms for the word 'rapid'...\nRESPONSE: Here are two synonyms for the word \"rapid\":\n\n1. Swift\n2. Quick\nTime: 1.84s ... TTFT: 3.00 ms (9.8 tok/s) | Tokens: 19\n\n--- Processing p3_light_heavy ---\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"PROMPT: \n<|begin_of_text|><|start_header_id|>user<|end_header_id|>\nWrite a detailed 600-word essay on how ar...\nRESPONSE: By 2035, artificial intelligence (AI) is expected to have a profound impact on the education sector, transforming the way students learn, teachers teach, and institutions operate. As AI technology continues to advance, it is likely to revolutionize the education system, bringing about significant changes in terms of accessibility, efficiency, and effectiveness. This essay will explore the potential transformations AI could bring to education, as well as the ethical, economic, and social implications that come with it.\n\nOne of the most significant areas where AI is expected to make a significant impact is in personalized learning. AI-powered adaptive learning systems will be able to analyze individual students' learning styles, abilities, and needs, providing tailored instruction and feedback. This will enable students to learn at their own pace, with AI adjusting the difficulty level and content to suit their progress. This personalized approach will lead to improved academic outcomes, increased student engagement, and reduced dropout rates.\n\nAI will also revolutionize the way teachers teach. With AI-powered teaching assistants, educators will be able to focus on more complex tasks, such as designing curriculum, assessing student progress, and providing emotional support. AI will help teachers to identify areas where students need extra support, allowing them to target their instruction more effectively. Additionally, AI-powered grading systems will free up teachers from tedious administrative tasks, enabling them to spend more time on what they do best – teaching and mentoring.\n\nAnother significant area where AI will make a significant impact is in language learning. AI-powered language learning platforms will be able to provide immersive, interactive, and engaging language lessons, allowing students to learn a new language at their own pace. AI will also enable real-time language translation, making it easier for students to communicate with native speakers and access global knowledge.\n\nAI will also transform the way educational institutions operate. AI-powered learning management systems will streamline administrative tasks, such as student registration, course scheduling, and grade tracking. AI will also enable institutions to better manage resources, optimize staffing, and improve student outcomes. Additionally, AI-powered chatbots will provide 24/7 support to students, helping them to resolve queries and access resources.\n\nHowever, the integration of AI in education also raises several ethical concerns. One of the most significant concerns is the potential for AI to perpetuate existing biases and inequalities. AI algorithms are only as good as the data they are trained on, and if the data is biased, the AI will learn to perpetuate those biases. This could lead to AI systems that are discriminatory and unfair. Therefore, it is essential that AI developers and educators work together to ensure that AI systems are fair, transparent, and inclusive.\n\nAnother ethical concern is the potential for AI to replace human teachers. While AI-powered teaching assistants will undoubtedly augment the teaching profession, it is essential that we ensure that human teachers are not replaced by AI. Human teachers bring a level of empathy, creativity, and emotional intelligence that AI systems cannot replicate. Therefore, it is essential that we strike a balance between AI-powered teaching assistants and human teachers.\n\nIn terms of economic implications, the integration of AI in education will likely lead to significant cost savings for educational institutions. AI-powered learning systems will reduce the need for human instructors, reducing labor costs. Additionally, AI-powered grading systems will eliminate the need for paper-based assessments, reducing the cost of materials and resources. However, it is essential that we ensure that the cost savings are not at the expense of student outcomes. AI must be used to enhance the learning experience, not to cut corners.\n\nIn terms of social implications, the integration of AI in education will likely lead to a more inclusive and accessible education system. AI-powered learning systems will enable students with disabilities to learn more effectively, providing them with personalized support and accommodations. Additionally, AI-powered language learning platforms will enable students from diverse linguistic backgrounds to access education and participate in global knowledge networks.\n\nIn conclusion, the integration of AI in education by 2035 will bring about significant transformations in the way students learn, teachers teach, and institutions operate. AI will enable personalized learning, language learning, and administrative efficiency, while also raising ethical, economic, and social implications. It is essential that we ensure that AI is used to enhance the learning experience, not to perpetuate existing biases and inequalities. By striking a balance between AI-powered teaching assistants and human teachers, we can create a more inclusive, accessible, and effective education system that benefits all students.\nTime: 73.10s ... TTFT: 2.89 ms (12.1 tok/s) | Tokens: 884\n\n--- Processing p4_light_heavy ---\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"PROMPT: \n<|begin_of_text|><|start_header_id|>user<|end_header_id|>\nTell a long, descriptive story about a ti...\nRESPONSE: The sun beat down on the dusty streets of ancient Thebes, casting a golden glow over the bustling city. Amidst the chaos, a figure emerged from the shadows, dressed in attire that seemed out of place among the ancient Egyptians. He was a time traveler, sent from a distant future to witness the wonders of the past.\n\nAs he walked, the air was filled with the sounds of hammers ringing out against stone, the scent of incense wafting from the temples, and the chatter of merchants haggling over goods. The time traveler's eyes widened in awe as he took in the vibrant colors and intricate hieroglyphics that adorned the buildings.\n\nHe approached a group of workers constructing a massive stone statue of the great pharaoh, Ramses II. The time traveler watched as they labored, their sweat-drenched bodies glistening in the sunlight. One of the workers, a young man with a strong jawline and piercing brown eyes, caught his attention.\n\n\"Ah, greetings, stranger,\" the young man said, his voice gruff from the heat and labor. \"What brings you to our city?\"\n\nThe time traveler, still adjusting to the ancient surroundings, hesitated before responding. \"I...I am a traveler from a far-off land. I've come to marvel at the wonders of your civilization.\"\n\nThe young man's eyes narrowed. \"You're not from around here, that's for certain. What's this 'far-off land' you speak of?\"\n\nThe time traveler hesitated, unsure how much to reveal. \"Let's just say I've come from a place where the gods are not as... tangible as they are here,\" he said, trying to gauge the young man's reaction.\n\nThe worker's eyes sparkled with curiosity. \"Ah, I see. Well, you're welcome to stay and learn from us. But be warned, stranger, our gods are not to be trifled with. They demand respect and offerings.\"\n\nAs the time traveler continued to explore the city, he found himself drawn to the majestic temples and the bustling markets. He marveled at the intricate carvings and the vibrant colors that adorned the buildings. He watched as the priests performed rituals, their chanting and incense wafting through the air.\n\nAs the sun began to set, the time traveler made his way to the banks of the Nile, where he found a group of people gathered around a brazier. They were roasting meats and vegetables, the aroma wafting through the air, and the sound of laughter and music filled the night air.\n\nThe time traveler approached a woman with a kind face and a warm smile. \"Greetings, good woman,\" he said, his eyes taking in the vibrant colors of her clothing. \"What is this feast you're enjoying?\"\n\nThe woman's eyes sparkled with warmth. \"Ah, we're celebrating the full moon. We feast and make offerings to the gods, asking for their blessings and protection.\"\n\nThe time traveler's eyes met hers, and he felt a sense of connection. \"I'd like to join you,\" he said, his voice filled with sincerity. \"I've come to learn and appreciate your culture.\"\n\nThe woman's smile grew wider. \"Then join us, stranger. We welcome those who seek to learn and understand.\"\n\nAs the night wore on, the time traveler found himself swept up in the joy and camaraderie of the feast. He laughed and chatted with the people, learning about their customs and traditions. He felt a sense of belonging, as if he had finally found a place where he could truly belong.\n\nAs the night drew to a close, the time traveler knew it was time to return to his own time. He bid farewell to the woman and the others, thanking them for their kindness and generosity.\n\nAs he disappeared into the night, the young man from the temple construction site appeared beside him. \"Farewell, stranger,\" he said, his eyes serious. \"Remember, the gods are always watching. Be sure to show them respect and gratitude.\"\n\nThe time traveler nodded, feeling a sense of gratitude and wonder. He knew that he would never forget this experience, this chance to connect with the people and culture of ancient Egypt. As he disappeared into the shadows, he felt a sense of longing, knowing that he would never forget the vibrant colors, the vibrant sounds, and the warmth of the people he had met.\n\nAnd as he vanished into the mists of time, the young man from the temple construction site looked up at the stars, his eyes filled with a sense of wonder and awe. He knew that the gods were always watching, and that the stranger's visit was a reminder of the power and majesty of their civilization.\nTime: 79.32s ... TTFT: 2.72 ms (12.1 tok/s) | Tokens: 959\n\n--- Processing p5_light_heavy ---\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"PROMPT: \n<|begin_of_text|><|start_header_id|>user<|end_header_id|>\nGenerate an in-depth tutorial explaining ...\nRESPONSE: **Introduction**\n\nAttention mechanisms are a crucial component of transformer models, revolutionizing the way neural networks process and understand sequential data. In this tutorial, we'll delve into the inner workings of attention mechanisms, exploring the mathematical concepts, analogies, and examples that make them tick.\n\n**What is Attention?**\n\nAttention is a mechanism that allows a neural network to selectively focus on specific parts of the input data, rather than treating the entire input as a single entity. This is particularly important when dealing with sequential data, such as sentences or time series, where the importance of each element can vary greatly.\n\n**The Need for Attention**\n\nImagine you're trying to understand a long, complex sentence. A traditional neural network would process each word individually, without considering the context in which it appears. This can lead to poor performance, as the network may not capture the nuances of the sentence.\n\nAttention mechanisms solve this problem by allowing the network to attend to specific parts of the input data, weighing their importance and combining the results. This enables the network to focus on the most relevant information, leading to improved performance.\n\n**The Attention Mechanism**\n\nThe attention mechanism consists of three main components:\n\n1. **Query** (Q): The query represents the current state of the network, often the output of the previous time step.\n2. **Key** (K): The key represents the input data, which is used to compute the attention weights.\n3. **Value** (V): The value represents the input data, which is used to compute the output.\n\n**Attention Calculation**\n\nThe attention calculation involves three main steps:\n\n1. **Query-Key Dot Product**: Compute the dot product of the query and key vectors, element-wise.\n2. **Softmax**: Apply the softmax function to the dot product, resulting in a probability distribution over the input data.\n3. **Weighted Sum**: Compute the weighted sum of the value vectors, using the attention weights from step 2.\n\nMathematically, this can be represented as:\n\n`Attention(Q, K, V) = Softmax(Q * K) * V`\n\nwhere `Q`, `K`, and `V` are the query, key, and value vectors, respectively.\n\n**Example**\n\nSuppose we have a sequence of 5 words: \"The quick brown fox jumps over the lazy dog\". We want to compute the attention weights for each word, given the previous word \"fox\".\n\n* Query (Q): `[0.5, 0.3, 0.2, 0.1, 0.1]` (representing the importance of each word)\n* Key (K): `[0.2, 0.5, 0.8, 0.1, 0.3]` (representing the importance of each word in the input sequence)\n* Value (V): `[1, 2, 3, 4, 5]` (representing the input sequence)\n\nThe attention calculation would be:\n\n`Attention(Q, K, V) = Softmax([0.5, 0.3, 0.2, 0.1, 0.1] * [0.2, 0.5, 0.8, 0.1, 0.3]) * [1, 2, 3, 4, 5]`\n\n`Attention(Q, K, V) = [0.25, 0.5, 0.75, 0.25, 0.5] * [1, 2, 3, 4, 5] = [0.25, 1, 2.25, 1, 2.5]`\n\nThe attention weights represent the importance of each word, given the previous word \"fox\". The output would be a weighted sum of the value vectors, resulting in a new representation that captures the most relevant information.\n\n**Multi-Head Attention**\n\nIn practice, we often use multi-head attention, which involves applying attention multiple times with different query, key, and value transformations. This allows the network to capture different aspects of the input data and improve performance.\n\n**Conclusion**\n\nAttention mechanisms are a powerful tool in transformer models, enabling neural networks to focus on the most relevant information in sequential data. By understanding the attention mechanism, you can better appreciate the capabilities and limitations of transformer models and apply them to a wide range of applications.\n\n**Additional Resources**\n\nFor further reading, I recommend:\n\n* The original paper on attention mechanisms: \"Attention Is All You Need\" by Vaswani et al. (2017)\n* A detailed tutorial on transformer models: \"Transformers: A Guide\" by Hugging Face\n* A comprehensive overview of attention mechanisms: \"Attention Mechanisms in Deep Learning\" by Stanford CS231n\n\nI hope this tutorial has provided a thorough introduction to attention mechanisms in transformer models. If you have any questions or\nTime: 83.12s ... TTFT: 2.42 ms (12.0 tok/s) | Tokens: 1001\n\n--- Processing p6_heavy_light ---\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"PROMPT: \n<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n[CONTEXT]\nThe following text is an excerp...\nRESPONSE: Based on the provided context, I'd be happy to help!\n\nAccording to historical records, the first Roman Emperor was Augustus Caesar, also known as Octavian. He was the grandnephew and adopted son of Julius Caesar and became the first emperor of Rome in 27 BC, marking the end of the Roman Republic.\nTime: 6.03s ... TTFT: 2.83 ms (11.1 tok/s) | Tokens: 68\n\n--- Processing p7_heavy_light ---\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"PROMPT: \n<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n[CONTEXT]\nIn this extensive passage, we d...\nRESPONSE: One commonly used activation function is the Sigmoid function.\nTime: 1.43s ... TTFT: 2.53 ms (8.4 tok/s) | Tokens: 13\n\n--- Processing p8_heavy_light ---\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"PROMPT: \n<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n[CONTEXT]\nYou are given a long transcript...\nRESPONSE: The main cause of the French Revolution was the widening economic and social disparities between the wealthy nobility and the impoverished commoners, exacerbated by the financial burdens of the American Revolutionary War and the Enlightenment ideas of liberté, égalité, fraternité, which fueled the demand for greater social and political equality.\nTime: 5.64s ... TTFT: 2.76 ms (11.2 tok/s) | Tokens: 64\n\n--- Processing p9_heavy_heavy ---\n","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"PROMPT: \n<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n[CONTEXT]\nImagine a detailed 1,000-token ...\nRESPONSE: **Policy Proposal: Accelerating the Transition to Renewable Energy in Developing Countries**\n\n**Executive Summary**\n\nThe global imperative to mitigate climate change demands a swift and collective response. Developing countries, which are disproportionately vulnerable to the impacts of climate change, must prioritize the transition to renewable energy to ensure sustainable development and economic growth. This proposal outlines a comprehensive strategy to support the transition to renewable energy in developing countries, leveraging international cooperation, technological innovation, and socioeconomic benefits.\n\n**I. Introduction**\n\nThe Intergovernmental Panel on Climate Change (IPCC) warns that the world has approximately 10 years to limit global warming to 1.5°C above pre-industrial levels. Developing countries, which account for approximately 80% of the world's population, are particularly vulnerable to climate change due to their limited resources and infrastructure. The transition to renewable energy is crucial for these countries to reduce their reliance on fossil fuels, improve energy access, and stimulate economic growth.\n\n**II. Current Challenges and Opportunities**\n\nDeveloping countries face significant barriers to adopting renewable energy, including:\n\n1. **Infrastructure**: Limited grid infrastructure and energy storage capacity hinder the integration of renewable energy sources.\n2. **Financing**: Access to capital and funding for renewable energy projects remains a significant challenge.\n3. **Skills and Capacity**: Insufficient workforce training and expertise in renewable energy technologies and maintenance.\n4. **Policy and Regulation**: Inadequate policy frameworks and regulatory environments hinder the development of renewable energy industries.\n\nDespite these challenges, developing countries are making progress in adopting renewable energy. For example:\n\n1. **Renewable energy targets**: Many developing countries have set ambitious renewable energy targets, such as India's goal of 40% of its energy mix from non-fossil fuels by 2030.\n2. **Renewable energy auctions**: Competitive bidding processes have driven down the cost of renewable energy, making it more competitive with fossil fuels.\n3. **Off-grid energy solutions**: Mini-grids and decentralized energy systems are providing energy access to remote and off-grid communities.\n\n**III. Policy Recommendations**\n\nTo accelerate the transition to renewable energy in developing countries, we recommend:\n\n1. **International Cooperation**: Establish a global partnership to mobilize financing, technology transfer, and capacity building for renewable energy projects in developing countries.\n2. **Renewable Energy Financing**: Create innovative financing mechanisms, such as green bonds, carbon credits, and public-private partnerships, to attract investment in renewable energy projects.\n3. **Training and Capacity Building**: Develop workforce training programs and capacity-building initiatives to enhance the skills and expertise of local workers in renewable energy technologies.\n4. **Policy and Regulatory Frameworks**: Develop and implement supportive policy and regulatory frameworks to encourage the development of renewable energy industries.\n5. **Grid Integration and Energy Storage**: Invest in grid infrastructure and energy storage solutions to ensure the reliable integration of renewable energy sources into the grid.\n6. **Research and Development**: Continue research and development in renewable energy technologies to improve efficiency, reduce costs, and increase adoption.\n7. **Public Awareness and Education**: Promote public awareness and education on the benefits of renewable energy, its role in mitigating climate change, and the importance of energy efficiency.\n\n**IV. Implementation and Monitoring**\n\nTo ensure the successful implementation of this policy proposal, we recommend:\n\n1. **Establish a Global Renewable Energy Task Force**: A multi-stakeholder platform to coordinate international cooperation, share best practices, and monitor progress.\n2. **Develop a Global Renewable Energy Roadmap**: A comprehensive plan outlining the necessary steps to achieve a global transition to renewable energy.\n3. **Establish a Renewable Energy Financing Facility**: A dedicated facility to provide financing for renewable energy projects in developing countries.\n4. **Monitor Progress and Report**: Regularly monitor progress, report on achievements, and identify areas for improvement.\n\n**Conclusion**\n\nThe transition to renewable energy in developing countries is a critical step towards a sustainable and climate-resilient future. This policy proposal outlines a comprehensive strategy to support the transition, leveraging international cooperation, technological innovation, and socioeconomic benefits. We urge governments, international organizations, and stakeholders to join forces to accelerate the global transition to renewable energy and ensure a more equitable and sustainable future for all.\nTime: 69.89s ... TTFT: 2.65 ms (12.1 tok/s) | Tokens: 845\n\n--- Processing p10_heavy_heavy ---\nPROMPT: \n<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n[CONTEXT]\nYou have just read a 700-token ...\nRESPONSE: The Industrial Revolution, which took place from the 18th to the 19th century, marked a significant turning point in human history. This period saw the transition from manual labor to machine-based manufacturing, transforming the way goods were produced and the economy functioned. Fast-forward to the present day, and we find ourselves in the midst of another technological revolution, driven by the advent of artificial intelligence (AI) and automation. In this essay, we will explore the parallels between the Industrial Revolution and the current AI-driven automation era, examining the technological advancements, labor implications, and potential consequences for society.\n\nOne of the most striking parallels between the two eras is the replacement of human labor by machines. During the Industrial Revolution, the introduction of steam-powered machines and the assembly line enabled mass production, leading to the displacement of many human workers. Similarly, in the current era, AI and automation are transforming industries, replacing jobs, and altering the nature of work. According to a report by the McKinsey Global Institute, up to 800 million jobs could be lost worldwide due to automation by 2030. This is not to say that AI-driven automation is solely responsible for job displacement, as other factors, such as globalization and technological advancements, also play a role. However, the trend is undeniable, and it is crucial to consider the implications for workers and society as a whole.\n\nAnother technological parallel between the two eras is the focus on efficiency and productivity. During the Industrial Revolution, the introduction of machines and factories enabled mass production, leading to increased efficiency and productivity. Similarly, AI-driven automation is designed to optimize processes, streamline operations, and reduce costs. For instance, AI-powered chatbots can handle customer inquiries, freeing up human customer service representatives to focus on more complex tasks. In manufacturing, AI-powered robots can perform tasks that were previously done by humans, such as assembly and quality control.\n\nHowever, just as the Industrial Revolution led to significant social and economic changes, AI-driven automation is also having a profound impact on society. One of the most pressing concerns is the potential for job displacement and income inequality. As AI takes over routine and repetitive tasks, many workers may find themselves without the skills to adapt to the changing job market. This could exacerbate income inequality, as those who possess the necessary skills and education are likely to benefit more from the new economy. Moreover, the concentration of wealth and power among the few who own the means of production, as was the case during the Industrial Revolution, could lead to social unrest and political instability.\n\nFurthermore, the rise of AI-driven automation raises questions about the nature of work and the human experience. As machines take over tasks that were previously done by humans, we are forced to reevaluate what it means to be human. Are we defined solely by our ability to work and produce? Or do we have a broader purpose and value beyond our economic contributions? The Industrial Revolution led to the emergence of a new class of workers, the working class, who were defined by their labor. In the current era, we are witnessing the emergence of a new class of workers, the \"gig economy\" workers, who are defined by their flexibility and adaptability.\n\nIn conclusion, the parallels between the Industrial Revolution and the current AI-driven automation era are striking. Both eras have seen the replacement of human labor by machines, the focus on efficiency and productivity, and significant social and economic changes. However, while the Industrial Revolution led to the emergence of a new class of workers and a new economy, the current era raises more profound questions about the nature of work and the human experience. As we navigate this new landscape, it is essential to prioritize the well-being of workers, invest in education and retraining programs, and ensure that the benefits of AI-driven automation are shared equitably among all members of society.\nTime: 62.57s ... TTFT: 2.85 ms (12.3 tok/s) | Tokens: 772\n\n--- FINAL REPORT (MONOLITHIC) ---\nTotal time to process all 10 requests (sequential): 385.42s\n[MONOLITHIC] Model unloaded and GPU memory cleaned.\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}